{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb626053",
   "metadata": {},
   "source": [
    "# Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3072c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py as h5\n",
    "from astropy.time import Time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sigpyproc\n",
    "from sigpyproc.readers import FilReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a493b5",
   "metadata": {},
   "source": [
    "# Definición de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2208ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para extraer información de archivos .hdf5 que da SpS\n",
    "#Esta función solo depende del camino que le pases así que funcionara\n",
    "#ya sea para el archivo .hdf5 que tenga la opción no filter, así como para\n",
    "#aquel que no la tenga. Le pasas el path, y te devuelve un dataframe con\n",
    "#toda la información de los candidatos, uno con toda la información de \n",
    "#los pulsos y otro con toda la información de los eventos\n",
    "\n",
    "def get_hdf5_out_df(camino):\n",
    "    path_hdf5 = camino\n",
    "    #Definimos los nombres de las columnas que vamos a levantar\n",
    "    #NOTA: aqui le llamo a la variable 'Sigma' de single_pulse_search_py SN, pero no es una SN como se calcula habitualmente\n",
    "    # La información sale del script 'single_pulse_search.py' mismo, donde describe lo siguiente:\n",
    "    #    -- The definition of \"sigma\" used is possibly slightly different\n",
    "    #   from that used in other codes for S/N:\n",
    "    #       sigma = sum(signal-bkgd_level)/RMS/sqrt(boxcar_width)\n",
    "    #   where the bkgd_level is typically 0 after detrending and RMS=1\n",
    "    #   after normalization.  This definition has the advantage that\n",
    "    #   you will get (basically) the same sigma for any pulse no\n",
    "    #   matter how much the input time series has been downsampled as\n",
    "    #   long as the pulse is still resolved.\n",
    "    # Copyright Scott Ransom <sransom@nrao.edu>, 2015\n",
    "    \n",
    "    column_cand = ['DM', 'Period', 'Time', 'SN', 'Rank', 'N_pulses', 'main_cand']\n",
    "    column_pulses = ['DM', 'SN', 'Time', 'Downfact', 'Time_org', 'N_events', 'Sample', 'Candidate', 'Rank']\n",
    "    column_events = ['DM', 'SN', 'Time', 'Downfact', 'Time_org', 'Sample', 'Pulse']\n",
    "    \n",
    "    #Leemos el archivo .hfd5\n",
    "    lect_hdf5 = h5.File(path_hdf5, 'r')\n",
    "\n",
    "    #Levanto la informacion de los candidatos\n",
    "    datacb0 = lect_hdf5[\"candidates/block0_values\"][:]\n",
    "    datacb1 = lect_hdf5[\"candidates/block1_values\"][:]\n",
    "    datacb2 = lect_hdf5[\"candidates/block2_values\"][:]\n",
    "\n",
    "    dc = np.hstack((datacb0, datacb1, datacb2))\n",
    "    candidates = pd.DataFrame(dc, columns = column_cand)\n",
    "\n",
    "    #Levanto la informacion de los pulsos\n",
    "    datapb0 = lect_hdf5[\"pulses/block0_values\"][:]\n",
    "    datapb1 = lect_hdf5[\"pulses/block1_values\"][:]\n",
    "    datapb2 = lect_hdf5[\"pulses/block2_values\"][:]\n",
    "    datapb3 = lect_hdf5[\"pulses/block3_values\"][:]\n",
    "\n",
    "    dp = np.hstack((datapb0, datapb1, datapb2, datapb3))\n",
    "    pulses = pd.DataFrame(dp, columns = column_pulses)\n",
    "\n",
    "    #Levanto la informacion de los eventos\n",
    "    dataeb0 = lect_hdf5[\"events/block0_values\"][:]\n",
    "    dataeb1 = lect_hdf5[\"events/block1_values\"][:]\n",
    "    dataeb2 = lect_hdf5[\"events/block2_values\"][:]\n",
    "\n",
    "    de = np.hstack((dataeb0, dataeb1, dataeb2))\n",
    "    events = pd.DataFrame(de, columns = column_events)\n",
    "    \n",
    "    return candidates, pulses, events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee2fec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para levantar la información de un archivo singlepulse\n",
    "# para armarme el dataframe que quiero usar, además, antes tengo \n",
    "# que extraer información del archivo .fil, como el mjdstart y pasarselo\n",
    "\n",
    "def get_pulsespresto_out_df(camino, mjdstart):\n",
    "    #Array que tiene toda la información de dentro de un singlepulse\n",
    "    #por algún motivo genial, las líneas del archivo que tienen un # adelante, no las levanta\n",
    "    data = np.loadtxt(camino)\n",
    "\n",
    "    #Para recopilar la información de la fecha del archivo la extraigo del nombre\n",
    "    # para que esto funcione, tiene que tener la siguiente forma el nombre\n",
    "    # del archivo singlepulse: '/all_sp_t_8SN_J1810-197_A2_20221231.singlepulse'\n",
    "    # porque levanta la cadena de string que esta luego del ultimo / y luego del\n",
    "    # ultimo _ y antes del .\n",
    "    # Date from path:\n",
    "    date_fpath = camino.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "    array_date = np.full(data.shape[0], np.int32(date_fpath))\n",
    "\n",
    "    #Armo un array que tenga la información del tstart para este día\n",
    "    array_mjdstart = np.full(data.shape[0], mjdstart)\n",
    "\n",
    "    #Concateno todos los arrays con la información de la fehca y el mjd de comienzo de la observación\n",
    "    array_pulses = np.concatenate((data, array_date.reshape(-1,1), array_mjdstart.reshape(-1,1)),axis=1)\n",
    "    #Creo un dataframe\n",
    "    column_pulsespresto = ['DM', 'SN', 'Time', 'Sample','Downsample', 'Date', 'MJD start']\n",
    "    pulsespresto = pd.DataFrame(array_pulses, columns = column_pulsespresto)\n",
    "    \n",
    "    return pulsespresto\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0b003d7-8535-437c-a200-7ca7d9ad3280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pulsespresto_filter(dataframe, dmmin, dmmax):\n",
    "    #Primer criterio para agrupar pulsos que voy a considerar son el mismo\n",
    "    #Este criterio va a ser, truncar el tiempo en el que ocurre el pulso\n",
    "    # y si es igual hasta la centesima, los agrupos. Luego, me quedo\n",
    "    # con aquel el pulso para el cual la SN es maxima dentro de los que\n",
    "    # tienen el mismo tiempo truncado. Y esos son los que \"considero pulsos\"\n",
    "    dataframe['Time trunc']=np.trunc(dataframe['Time']*100)/100\n",
    "    criterio = dataframe.groupby('Time trunc')['SN'].max()\n",
    "    dataframe_filtered1 = dataframe[dataframe.apply(lambda row: row['SN'] == criterio[row['Time trunc']],axis=1)]\n",
    "\n",
    "    #Luego, el otro filtro que aplico, es que el DM para el cual tenga la máxima\n",
    "    # SN, sea +-10 alrededor del Dm del objeto, esto en realidad lo puedo especificar\n",
    "    #en los parametros que le paso a esta funcion\n",
    "    result_presto_sps = dataframe_filtered1[(dataframe_filtered1.DM > dmmin) & (dataframe_filtered1.DM< dmmax)]\n",
    "\n",
    "    \n",
    "    return result_presto_sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c829c5cd-fedd-4c90-8138-3f5b72484df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_fordm(dataframe, dmmin, dmmax):\n",
    "    #el objetivo de esta función, es filtrar por dm cualquier dataframe, \n",
    "    #esta pensando en realidad para filtrar los dataframe que salen de los\n",
    "    #archivos .hdf5, pero si por algun motivo no funciono el filtro\n",
    "    #en pulsespresot_filter, podría usarse también. \n",
    "\n",
    "    dataframe_filtered = dataframe[(dataframe.DM > dmmin) & (dataframe.DM <dmmax)]\n",
    "    return dataframe_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e98ad903-476c-4fa1-a7c8-13427c26e5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_presto_sps(dfpresto: pd.DataFrame, dfcand: pd.DataFrame, dfpuls: pd.DataFrame, spsoption: str):\n",
    "    datatocompare = dfpresto[['DM','SN','Time', 'Sample','Date', 'MJD start']].copy()\n",
    "    cols_to_cand = ['DM']\n",
    "    cols_to_puls = ['SN', 'DM', 'Sample']\n",
    "\n",
    "    #Evaluo si en las columnas de los datos de presto, en las columnas especificadas, hay alguna fila que tenga el mismo valor que\n",
    "    #en el dataframe a comparar, ya sea el de candidatos o el de pulsos\n",
    "\n",
    "    #En el caso del dataframe de candidatos comparo solamente si hay pulsos en el dataframe de presto que tengan el mismo valor de DM que\n",
    "    #aparece para los candidatos. Este criterio, va a dar 'True' si no hay nadie, por eso luego cuando creo la columna a agregar en el dataframe\n",
    "    #lo niego, así es True cuando SÍ hay un candidato con ese valor de DM.\n",
    "    no_match_results_cand = datatocompare[~datatocompare[cols_to_cand].apply(tuple, axis=1).isin(dfcand[cols_to_cand].apply(tuple, axis=1))]\n",
    "\n",
    "    #El procedimiento para la comparación con el dataframe de pulsos es el mismo, solamente que en este caso, lo que comparo es la SN, el DM\n",
    "    #y el número de Sample (creo que el número de sample ES CASI Q EL DNI).\n",
    "    no_match_results_pul = datatocompare[~datatocompare[cols_to_puls].apply(tuple, axis=1).isin(dfpuls[cols_to_puls].apply(tuple, axis=1))]\n",
    "\n",
    "    results_firstcom['Hay candi con = DM'] = ~results_firstcom.index.isin(no_match_results_cand.index)\n",
    "    results_firstcom['Esta pulses'] = ~results_firstcom.index.isin(no_match_results_pul.index)\n",
    "\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89fdaa5-f205-4b4c-bc82-bee15c801d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
